{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def percentage_improvement(old_error, new_error):\n",
    "    \"\"\"\n",
    "    Calculates the percentage improvement between two error values.\n",
    "\n",
    "    Args:\n",
    "      old_error: The old error value.\n",
    "      new_error: The new error value.\n",
    "\n",
    "    Returns:\n",
    "      The percentage improvement, as a float.\n",
    "    \"\"\"\n",
    "\n",
    "    # return (new_error - old_error) / old_error * 100\n",
    "    return (old_error - new_error) / old_error * 100\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # data = [(2.040, 0.608), (40.797, 0.040), (0.916, 0.061), (58.580, 0.118)]\n",
    "    # data = [(2.194, 0.556), (2.613, 0.787), (260.249, 0.112), (106.582, 0.080)]\n",
    "\n",
    "    # Complex medium 1000Hz (real, Imag), 1500Hz (real, Imag)\n",
    "    data = [(3.190, 0.087), (2.632, 0.045), (1.322, 0.043), (3.486, 0.094)]\n",
    "\n",
    "    for i in data:\n",
    "        result = percentage_improvement(old_error=i[0], new_error=i[1])\n",
    "\n",
    "        print(\"The percentage improvement is\", result, \"%.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T06:55:43.495832700Z",
     "start_time": "2024-04-09T06:55:43.476261800Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Complex NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import pi, power, savetxt\n",
    "\n",
    "from pinn.complex.ComplexNN import PINN_CMPLX\n",
    "from utils.dataset_utils import plot_output_complex\n",
    "\n",
    "def complex_medium_delany_bazley(f: int = 100, c: int = 340, rho: float = 1.225, e: int = 250) -> complex:\n",
    "    \"\"\"\n",
    "    SPEED OF SOUND IN COMPLEX MEDIUM DELANY BAZLEY\n",
    "    :param f: Frequency (Hz)\n",
    "    :param c: Speed of sound (m/s)\n",
    "    :param rho: Constant\n",
    "    :param e: Flow resistance (rayls/m)\n",
    "    :return cw: Speed of sound in Complex domain\n",
    "    \"\"\"\n",
    "    omega = 2 * pi * f\n",
    "    k0 = omega / c\n",
    "    X = rho * f / e\n",
    "    kw = k0 * (1 + (0.0978 * power(X, -0.7)) - (1j * 0.189 * power(X, -0.595)))\n",
    "    cw = omega/kw\n",
    "    return cw\n",
    "\n",
    "def export_data(arr, export_path, filename):\n",
    "    if not os.path.exists(export_path):\n",
    "        os.makedirs(export_path)\n",
    "\n",
    "    print(len(arr))\n",
    "    savetxt(f'{export_path}/{filename}.csv', arr, delimiter=',')\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(f'{export_path}/{filename}.csv', header=None)\n",
    "    df= df.T\n",
    "    df.columns = ['test_data', 'gt_real', 'nn_out_real', 'gt_imag', 'nn_out_imag']\n",
    "\n",
    "\n",
    "    # Save the transposed DataFrame to a CSV file\n",
    "    df.to_csv(f'{export_path}/{filename}.csv', index=False)\n",
    "    print(f\"Exported data to: {export_path}/{filename}.csv\")\n",
    "    # df.to_csv(f'{export_path}/data_relative_error.csv')\n",
    "    # print(f\"Exported data to: {export_path}/data_relative_error.csv\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    DLRS = True\n",
    "\n",
    "    # Variables associated with physics\n",
    "    F = 1500                                 # Frequency\n",
    "    C = 340                                 # Speed of sound\n",
    "    RHO = 1.225\n",
    "    E = 250\n",
    "    CW = complex_medium_delany_bazley(F, C, RHO, E)\n",
    "\n",
    "    X_LB = 0.0                                # Left boundary\n",
    "    X_RB = 1.0                                # Right boundary\n",
    "    P_LB = 1.0 + 0.0j                         # Pressure at the left boundary\n",
    "    P_RB = -1.0 + 0.0j                        # Pressure at the right boundary\n",
    "    K = 2 * pi * F / CW                    # Wave number\n",
    "\n",
    "    if DLRS:\n",
    "        experiment_name = f'dlrs/{F}Hz'\n",
    "        filename = f'dlrs_{F}Hz'\n",
    "    else:\n",
    "        experiment_name = f'std/{F}Hz'\n",
    "        filename = f'std_{F}Hz'\n",
    "\n",
    "    # Initialize the PINN model\n",
    "    NN = PINN_CMPLX(frequency=F, exp_name=experiment_name, cw=CW, x_lb=X_LB, x_rb=X_RB, p_lb=P_LB, p_rb=P_RB)\n",
    "    NN.load_model(path=f'./weights/CMPLX/complex_medium/{experiment_name}_last')\n",
    "\n",
    "    export_dict = plot_output_complex(F, K, P_LB, P_RB, NN)\n",
    "\n",
    "    # test_data = export_dict['test_data']\n",
    "    # S_r = export_dict['ground_truth_real']\n",
    "    # D_r = export_dict['nn_output_real']\n",
    "    # S_i = export_dict['ground_truth_imaginary']\n",
    "    # D_i = export_dict['nn_output_imaginary']\n",
    "\n",
    "    # arr = [test_data, S_r, D_r, S_i, D_i]\n",
    "    # export_path =  f'outputs/exports/complex/complex_medium/{experiment_name}'\n",
    "    # export_path = r\"C:\\Users\\Ashwi\\Documents\\Research\\POMA\\graphs\\delaney_bazley\\relative_error/\"\n",
    "\n",
    "    # export_data(arr, export_path, filename)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T06:52:24.697999500Z",
     "start_time": "2024-04-09T06:52:23.729147700Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tensorboard logs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "def export(filepath, outfile_path, filename, tag='loss'):\n",
    "    # Retrieve the events data\n",
    "    data = []\n",
    "    for event in tf.compat.v1.train.summary_iterator(filepath):\n",
    "        for value in event.summary.value:\n",
    "            # event.wall_time, event.step, value.tag, tf.make_ndarray(value.tensor)\n",
    "            if value.tag == tag:\n",
    "                data.append([event.step, tf.make_ndarray(value.tensor)])\n",
    "                # data.append([event.step, value.simple_value])  # pytorch exports\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['epoch', f'{tag.lower()}'])\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    output_file = f\"{outfile_path}/{filename}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Tensorboard logs successfully extracted and saved to {output_file}.\")\n",
    "\n",
    "\n",
    "def gather_file_paths(directory):\n",
    "    path_list = []\n",
    "    # parse directories\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if len(files) > 0:\n",
    "            for file in files:\n",
    "                # print(\"Current directory:\", root)\n",
    "                # print(\"Subdirectories:\", dirs)\n",
    "                # print(\"File:\", file)\n",
    "                # print(\"--------------------\")\n",
    "                path_list.append(os.path.join(root, file))\n",
    "    return path_list\n",
    "\n",
    "\n",
    "def get_tags(filename):\n",
    "    tags = []\n",
    "    for event in tf.compat.v1.train.summary_iterator(filename):\n",
    "        for value in event.summary.value:\n",
    "            # event.wall_time, event.step, value.tag, tf.make_ndarray(value.tensor)\n",
    "            if value.tag in tags:\n",
    "                break\n",
    "            else:\n",
    "                tags.append(value.tag)\n",
    "\n",
    "    return tags"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T11:06:16.410670800Z",
     "start_time": "2024-04-08T11:06:14.077278900Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "log_dir = r\"logs/complex/complex_medium/std/1500Hz\"\n",
    "\n",
    "filepaths = gather_file_paths(log_dir)\n",
    "\n",
    "for path in filepaths:\n",
    "    tags = get_tags(path)\n",
    "\n",
    "    if len(tags) != 0:\n",
    "        print(tags)\n",
    "        break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:45:05.556858Z",
     "start_time": "2024-04-08T10:45:05.418041600Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Export for PINNs dataset\n",
    "for path in filepaths:\n",
    "    parent_dir = os.path.dirname(path[5:])[:-6]\n",
    "    export(path, outfilename=parent_dir, tag='loss')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:45:13.876501100Z",
     "start_time": "2024-04-08T10:45:13.557281100Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Express export"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "f = 1500\n",
    "DLRS = True\n",
    "\n",
    "if DLRS:\n",
    "    filename = f'dlrs_{f}Hz'\n",
    "    log_dir = fr\"logs/complex/complex_medium/dlrs/{f}Hz\"\n",
    "else:\n",
    "    filename = f'std_{f}Hz'\n",
    "    log_dir = fr\"logs/complex/complex_medium/std/{f}Hz\"\n",
    "\n",
    "outfile_path = r\"C:\\Users\\Ashwi\\Documents\\Research\\POMA\\graphs\\delaney_bazley\\loss/\"\n",
    "\n",
    "filepaths = gather_file_paths(log_dir)\n",
    "\n",
    "for path in filepaths:\n",
    "    export(path, outfile_path, filename,tag='loss')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T11:07:07.665151300Z",
     "start_time": "2024-04-08T11:07:07.073571400Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
